{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maskinlæring og Prædiktiv Modellering for DLBCL\n",
    "\n",
    "Dette læringsforløb vil introducere dig til maskinlæring og hvordan det kan bruges til at forudsige behandlingsresultater for Diffuse Large B-Cell Lymphoma (DLBCL). Vi vil bruge Python og nogle populære biblioteker til dataanalyse, modellering og visualisering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 1: Introduktion til Maskinlæring\n",
    "\n",
    "### Hvad er maskinlæring?\n",
    "Maskinlæring er en metode, hvor computere lærer fra data og kan træffe beslutninger uden at være eksplicit programmeret til det. Der er forskellige typer af maskinlæring:\n",
    "- **Supervised Learning**: Computeren lærer fra mærkede data og forudsiger udfald baseret på inputdata.\n",
    "- **Unsupervised Learning**: Computeren finder mønstre i data uden mærkede udfald.\n",
    "- **Reinforcement Learning**: Computeren lærer ved at interagere med et miljø og modtage feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Værktøjer og Biblioteker\n",
    "Vi vil bruge følgende Python-biblioteker i dette forløb:\n",
    "- **NumPy**: Til numeriske beregninger.\n",
    "- **Pandas**: Til datamanipulation og analyse.\n",
    "- **Scikit-learn**: Til maskinlæring.\n",
    "- **Matplotlib**: Til visualisering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse: Opstilling af Miljø\n",
    "Lad os først sikre, at vi har de nødvendige biblioteker installeret. Kør nedenstående kommando for at installere dem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 2: Databehandling og Forberedelse\n",
    "\n",
    "### Hentning af Data fra NCBI\n",
    "Vi vil bruge et eksempel på et datasæt relateret til DLBCL. Normalt kan man hente data fra NCBI ved hjælp af Biopython, men her vil vi indlæse et lokalt datasæt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Indlæs data fra en lokal fil (eksempeldata)\n",
    "data = pd.read_csv('dlbcl_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataforberedelse\n",
    "Før vi kan bruge data til maskinlæring, skal vi rense og forberede det:\n",
    "- Fjerne rækker med manglende værdier.\n",
    "- Normalisere data, så de er på samme skala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fjern rækker med manglende værdier\n",
    "data = data.dropna()\n",
    "\n",
    "# Standardiser data\n",
    "data = (data - data.mean()) / data.std()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 3: Feature Engineering og Selektion\n",
    "\n",
    "### Feature Engineering\n",
    "Vi kan skabe nye features baseret på eksisterende data. For eksempel kan vi kombinere eller transformere nogle kolonner.\n",
    "\n",
    "### Feature Selektion\n",
    "Vi kan bruge statistiske metoder til at vælge de mest relevante features til vores model. Her bruger vi ANOVA F-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Antag at 'target' er vores målvariabel\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Vælg de 10 bedste features\n",
    "X_new = SelectKBest(f_classif, k=10).fit_transform(X, y)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 4: Bygning af Maskinlæringsmodeller\n",
    "\n",
    "### Supervised Learning Algoritmer\n",
    "Vi vil fokusere på klassifikationsalgoritmer som Logistic Regression, Random Forest og Support Vector Machine.\n",
    "\n",
    "### Modeltræning og Evaluering\n",
    "Vi deler data i trænings- og test-sæt, træner en model og evaluerer dens ydeevne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Opdel data i trænings- og test-sæt\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Træn en Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluer modellen\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 5: Avancerede Modeller og Hyperparameter Tuning\n",
    "\n",
    "### Avancerede Modeller\n",
    "Vi kan bruge avancerede modeller som Gradient Boosting og XGBoost samt neurale netværk med TensorFlow og Keras.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "Vi kan optimere modelparametre ved hjælp af Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definer parameterrum for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid Search med cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 6: Model Implementering og Fortolkning\n",
    "\n",
    "### Model Implementering\n",
    "Vi kan implementere den trænede model i et produktionsmiljø og bruge den til prædiktiv analyse i kliniske indstillinger.\n",
    "\n",
    "### Model Fortolkning\n",
    "Vi kan bruge værktøjer som SHAP til at
