{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maskinlæring og Prædiktiv Modellering for DLBCL\n",
    "\n",
    "Dette læringsforløb vil introducere dig til maskinlæring og hvordan det kan bruges til at forudsige behandlingsresultater for Diffuse Large B-Cell Lymphoma (DLBCL). Vi vil bruge Python og nogle populære biblioteker til dataanalyse, modellering og visualisering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 1: Introduktion til Maskinlæring\n",
    "\n",
    "### Hvad er maskinlæring?\n",
    "Maskinlæring er en metode, hvor computere lærer fra data og kan træffe beslutninger uden at være eksplicit programmeret til det. Der er forskellige typer af maskinlæring:\n",
    "- **Supervised Learning**: Computeren lærer fra mærkede data og forudsiger udfald baseret på inputdata.\n",
    "- **Unsupervised Learning**: Computeren finder mønstre i data uden mærkede udfald.\n",
    "- **Reinforcement Learning**: Computeren lærer ved at interagere med et miljø og modtage feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Værktøjer og Biblioteker\n",
    "Vi vil bruge følgende Python-biblioteker i dette forløb:\n",
    "- **NumPy**: Til numeriske beregninger.\n",
    "- **Pandas**: Til datamanipulation og analyse.\n",
    "- **Scikit-learn**: Til maskinlæring.\n",
    "- **Matplotlib**: Til visualisering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse: Opstilling af Miljø\n",
    "Lad os først sikre, at vi har de nødvendige biblioteker installeret. Kør nedenstående kommando for at installere dem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 2: Databehandling og Forberedelse\n",
    "\n",
    "### Hentning af Data fra NCBI\n",
    "Vi vil bruge et eksempel på et datasæt relateret til DLBCL. Vi henter datasættet `GSE10846` fra NCBI GEO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Indlæs data fra den downloadede fil\n",
    "data = pd.read_csv('GSE10846_series_matrix.txt.gz', sep='\\t', comment='!', index_col=0)\n",
    "\n",
    "# Vis de første par rækker af datasættet\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataforberedelse\n",
    "Før vi kan bruge data til maskinlæring, skal vi rense og forberede det:\n",
    "- Fjerne rækker med manglende værdier.\n",
    "- Normalisere data, så de er på samme skala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fjern rækker med manglende værdier\n",
    "data = data.dropna()\n",
    "\n",
    "# Standardiser data\n",
    "data = (data - data.mean()) / data.std()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 3: Feature Engineering og Selektion\n",
    "\n",
    "### Feature Engineering\n",
    "Vi kan skabe nye features baseret på eksisterende data. For eksempel kan vi kombinere eller transformere nogle kolonner.\n",
    "\n",
    "### Feature Selektion\n",
    "Vi kan bruge statistiske metoder til at vælge de mest relevante features til vores model. Her bruger vi ANOVA F-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Antag at 'target' er vores målvariabel\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Vælg de 10 bedste features\n",
    "X_new = SelectKBest(f_classif, k=10).fit_transform(X, y)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 4: Bygning af Maskinlæringsmodeller\n",
    "\n",
    "### Supervised Learning Algoritmer\n",
    "Vi vil fokusere på klassifikationsalgoritmer som Logistic Regression, Random Forest og Support Vector Machine.\n",
    "\n",
    "### Modeltræning og Evaluering\n",
    "Vi deler data i trænings- og test-sæt, træner en model og evaluerer dens ydeevne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Opdel data i trænings- og test-sæt\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Træn en Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluer modellen\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 5: Avancerede Modeller og Hyperparameter Tuning\n",
    "\n",
    "### Avancerede Modeller\n",
    "Vi kan bruge avancerede modeller som Gradient Boosting og XGBoost samt neurale netværk med TensorFlow og Keras.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "Vi kan optimere modelparametre ved hjælp af Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definer parameterrum for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid Search med cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul 6: Model Implementering og Fortolkning\n",
    "\n",
    "### Model Implementering\n",
    "Vi kan implementere den trænede model i et produktionsmiljø og bruge den til prædiktiv analyse i kliniske indstillinger.\n",
    "\n",
    "### Model Fortolkning\n",
    "Vi kan bruge værktøjer som SHAP til at forklare modelens beslutningsprocesser og vurdere eventuel bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Beregn SHAP værdier\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP værdier\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ressourcer og Referencer\n",
    "- **NCBI**: [https://www.ncbi.nlm.nih.gov/](https://www.ncbi.nlm.nih.gov/)\n",
    "- **Scikit-learn Dokumentation**: [https://scikit-learn.org/stable/documentation.html](https://scikit-learn.org/stable/documentation.html)\n",
    "- **Kaggle**: [https://www.kaggle.com/](https://www.kaggle.com/) (Datasæt og konkurrencer)\n",
    "- **Biopython Dokumentation**: [https://biopython.org/wiki/Documentation](https://biopython.org/wiki/Documentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
